{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os, time, collections\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "from nltk import agreement\n",
    "from statsmodels.stats import inter_rater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r'results/ratings_overview/' \n",
    "allFiles = glob.glob(path + \"/*.csv\")\n",
    "list_ = []\n",
    "for f in allFiles:\n",
    "    df = pd.read_csv(f,index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "feedback = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = r'results/dataset_entities/' \n",
    "allFiles = glob.glob(path + \"/*.txt\")\n",
    "dataset = {}\n",
    "for f in allFiles:\n",
    "    name = 'datset'\n",
    "    entities = pd.read_csv(f, index_col=None, header=None)\n",
    "    dataset[name] = set(list(entities[0]))\n",
    "    \n",
    "path = r'results/method_entities/' \n",
    "allFiles = glob.glob(path + \"/*.txt\")\n",
    "method = {}\n",
    "for f in allFiles:\n",
    "    name = 'method'\n",
    "    entities = pd.read_csv(f, index_col=None, header=None)\n",
    "    method[name] = set(list(entities[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "method_annotated = feedback.loc[(feedback['facet'] == \"method\")]\n",
    "dataset_annotated = feedback.loc[(feedback['facet'] == \"dataset\")]\n",
    "\n",
    "# dataset_annotated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What % of entities did get user feedback? \n",
    "- For those entities which have feedback from 2 or more people, what is the inter anotator agreement?\n",
    "- What % of dataset / method entities where considered correct / incorrect by the majority? (note: there is not necessarily always a majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "\n",
    "# for paper in dataset.keys():\n",
    "#     print(paper)\n",
    "#     print(len(dataset_annotated.loc[(dataset_annotated['paper_id'] == \"'\" + paper + \"'\")].groupby(['entity_text'])['paper_id'].count()))\n",
    "#     print(len(dataset[paper]))\n",
    "#     print(len(dataset_annotated.loc[(dataset_annotated['paper_id'] == \"'\" + paper + \"'\")].groupby(['entity_text'])['paper_id'].count()) / len(dataset[paper]))\n",
    "#     i = len(dataset[paper]) + i\n",
    "\n",
    "# print('')\n",
    "# print(len(dataset_annotated.entity_text.unique()) / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "57/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_relevant = dataset_annotated.loc[(dataset_annotated['relevant'] == \"relevant\")].groupby(['entity_text']).count()\n",
    "len(dataset_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2807017543859649"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16/57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for paper in method.keys():\n",
    "#     print(paper)\n",
    "#     print(len(method_annotated.loc[(method_annotated['paper_id'] == \"'\" + paper + \"'\")].groupby(['entity_text'])['paper_id'].count()))\n",
    "#     print(len(method[paper]))\n",
    "#     print(len(method_annotated.loc[(method_annotated['paper_id'] == \"'\" + paper + \"'\")].groupby(['entity_text'])['paper_id'].count()) / len(method[paper]))\n",
    "#     i = len(method[paper]) + i\n",
    "\n",
    "# print('')\n",
    "# print(len(method_annotated.entity_text.unique()) / i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "method_relevant = method_annotated.loc[(method_annotated['relevant'] == \"relevant\")].groupby(['entity_text']).count() \n",
    "len(method_relevant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36486486486486486"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "27/74\n",
    "\n",
    "# print(dataset_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H2> Annotator Agreement </H2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Dataset Entities </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/pandas/core/generic.py:3485: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    }
   ],
   "source": [
    "cleanup_nums = {\"relevant\": {\"relevant\": 1, \"irrelevant\": 0}}\n",
    "dataset_annotated.replace(cleanup_nums, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5166099089742238\n",
      "76\n"
     ]
    }
   ],
   "source": [
    "dataset_agreement = pd.DataFrame(index = dataset_annotated.entity_text.unique())\n",
    "\n",
    "pairs_count = 0\n",
    "kappas = []\n",
    "\n",
    "users = dataset_annotated.user_id.unique()\n",
    "for usr1 in dataset_annotated.user_id.unique():\n",
    "    ann1 = dataset_annotated.loc[dataset_annotated['user_id'] == usr1][['entity_text', 'relevant']]\n",
    "    ann1 = ann1.rename(columns={'relevant' : usr1})\n",
    "    \n",
    "    for usr2 in dataset_annotated.user_id.unique():\n",
    "        if(usr1 == usr2): continue\n",
    "        dataset_agreement = pd.DataFrame(index = dataset_annotated.entity_text.unique())\n",
    "        dataset_agreement = dataset_agreement.merge(ann1, left_index=True, right_on='entity_text', how='left').set_index('entity_text')\n",
    "\n",
    "        annotation = dataset_annotated.loc[dataset_annotated['user_id'] == usr2][['entity_text', 'relevant']]\n",
    "        annotation = annotation.rename(columns={'relevant' : usr2})\n",
    "        dataset_agreement = dataset_agreement.merge(annotation, left_index=True, right_on='entity_text', how='left').set_index('entity_text')\n",
    "    \n",
    "        df = dataset_agreement[~dataset_agreement.index.duplicated(keep='first')]\n",
    "        df['null_count'] = df.isnull().sum(axis=1)\n",
    "        df = df.sort_values('null_count', ascending=True)\n",
    "        dataset_agreement = df.drop('null_count', axis=1).dropna()\n",
    "        if(dataset_agreement.shape[0] > 20):\n",
    "            pairs_count+=1\n",
    "            taskdata = ([[0,str(i),str(dataset_agreement[usr1][i])] for i in range(0, len(dataset_agreement))] + [[1,str(i),str(dataset_agreement[usr2][i])] for i in range(0, len(dataset_agreement))])\n",
    "#             print(taskdata)\n",
    "            ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "            try: \n",
    "                kappa_val = ratingtask.kappa()\n",
    "            \n",
    "#                 print(\"kappa \" +str(kappa_val))\n",
    "                if not (kappa_val == 0.0 or kappa_val == 1.0): kappas.append(kappa_val)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "print(sum(kappas)/len(kappas))\n",
    "print(len(kappas))\n",
    "                    \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/pandas/core/generic.py:3485: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    }
   ],
   "source": [
    "cleanup_nums = {\"relevant\":     {\"relevant\": 1, \"irrelevant\": 0}}\n",
    "method_annotated.replace(cleanup_nums, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6384723079974136\n",
      "68\n"
     ]
    }
   ],
   "source": [
    "method_agreement = pd.DataFrame(index = method_annotated.entity_text.unique())\n",
    "\n",
    "pairs_count = 0\n",
    "kappas = []\n",
    "\n",
    "users = method_annotated.user_id.unique()\n",
    "for usr1 in method_annotated.user_id.unique():\n",
    "    ann1 = method_annotated.loc[method_annotated['user_id'] == usr1][['entity_text', 'relevant']]\n",
    "    ann1 = ann1.rename(columns={'relevant' : usr1})\n",
    "    \n",
    "    for usr2 in method_annotated.user_id.unique():\n",
    "        if(usr1 == usr2): continue\n",
    "        method_agreement = pd.DataFrame(index = method_annotated.entity_text.unique())\n",
    "        method_agreement = method_agreement.merge(ann1, left_index=True, right_on='entity_text', how='left').set_index('entity_text')\n",
    "\n",
    "        annotation = method_annotated.loc[method_annotated['user_id'] == usr2][['entity_text', 'relevant']]\n",
    "        annotation = annotation.rename(columns={'relevant' : usr2})\n",
    "        method_agreement = method_agreement.merge(annotation, left_index=True, right_on='entity_text', how='left').set_index('entity_text')\n",
    "    \n",
    "        df = method_agreement[~method_agreement.index.duplicated(keep='first')]\n",
    "        df['null_count'] = df.isnull().sum(axis=1)\n",
    "        df = df.sort_values('null_count', ascending=True)\n",
    "        method_agreement = df.drop('null_count', axis=1).dropna()\n",
    "        if(method_agreement.shape[0] > 20):\n",
    "            pairs_count+=1\n",
    "            taskdata = ([[0,str(i),str(method_agreement[usr1][i])] for i in range(0, len(method_agreement))] + [[1,str(i),str(method_agreement[usr2][i])] for i in range(0, len(method_agreement))])\n",
    "#             print(taskdata)\n",
    "            ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "            try: \n",
    "                kappa_val = ratingtask.kappa()\n",
    "            \n",
    "#                 print(\"kappa \" +str(kappa_val))\n",
    "                if not (kappa_val == 0.0 or kappa_val == 1.0): kappas.append(kappa_val)\n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "print(sum(kappas)/len(kappas))\n",
    "print(len(kappas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset_agreement = pd.DataFrame(index = dataset_annotated.entity_text.unique())\n",
    "\n",
    "# for user in dataset_annotated.user_id.unique():\n",
    "#    annotation = dataset_annotated.loc[dataset_annotated['user_id'] == user][['entity_text', 'relevant']]\n",
    "#    annotation = annotation.rename(columns={'relevant' : user})\n",
    "# #    if(user == \"diuSsjdsEoWWDTejfcpU6vaAbjt1\"): print(annotation)\n",
    "#    dataset_agreement = dataset_agreement.merge(annotation, left_index=True, right_on='entity_text', how='left').set_index('entity_text')\n",
    "    \n",
    "#    dataset_agreement_t = dataset_agreement.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset_agreement = dataset_agreement.as_matrix()\n",
    "# dataset_agreement = dataset_agreement.values\n",
    "# dataset_agreement_t = dataset_agreement_t.values\n",
    "\n",
    "# dataset_agreement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inter_rater.fleiss_kappa(dataset_agreement_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diuSsjdsEoWWDTejfcpU6vaAbjt1</th>\n",
       "      <th>YdJDigrdTZUOiUKMsMv1ciWxHtc2</th>\n",
       "      <th>Nq119A7Qa4hPWNSThUX3S8Y8k313</th>\n",
       "      <th>qV1wemRqtjWRBxqOnqDpbEDE7dQ2</th>\n",
       "      <th>XnqHi69zi9gmO4e7xFe6aK9PEiE3</th>\n",
       "      <th>G8hHT8mWZiXmaJTPIyLj6KdjzVF2</th>\n",
       "      <th>lqmIlg05OpMYR8f6VR9UPN29nWg2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_text</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>whether</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slashdot</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wikipedia</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social network</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>related work</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social networks</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>although</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epinions</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>without</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social media</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>named entities</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toward</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>equivalently</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>part of</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whereas</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximum entropy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive edges</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lower status</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>guha</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive relationships</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>social computing</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        diuSsjdsEoWWDTejfcpU6vaAbjt1  \\\n",
       "entity_text                                            \n",
       "whether                                          0.0   \n",
       "slashdot                                         1.0   \n",
       "wikipedia                                        1.0   \n",
       "social network                                   0.0   \n",
       "related work                                     0.0   \n",
       "social networks                                  0.0   \n",
       "although                                         0.0   \n",
       "epinions                                         1.0   \n",
       "without                                          0.0   \n",
       "social media                                     0.0   \n",
       "named entities                                   0.0   \n",
       "toward                                           0.0   \n",
       "equivalently                                     0.0   \n",
       "part of                                          0.0   \n",
       "whereas                                          0.0   \n",
       "maximum entropy                                  0.0   \n",
       "positive edges                                   0.0   \n",
       "lower status                                     0.0   \n",
       "guha                                             0.0   \n",
       "positive relationships                           0.0   \n",
       "social computing                                 0.0   \n",
       "\n",
       "                        YdJDigrdTZUOiUKMsMv1ciWxHtc2  \\\n",
       "entity_text                                            \n",
       "whether                                          0.0   \n",
       "slashdot                                         1.0   \n",
       "wikipedia                                        1.0   \n",
       "social network                                   1.0   \n",
       "related work                                     0.0   \n",
       "social networks                                  0.0   \n",
       "although                                         0.0   \n",
       "epinions                                         1.0   \n",
       "without                                          0.0   \n",
       "social media                                     1.0   \n",
       "named entities                                   1.0   \n",
       "toward                                           0.0   \n",
       "equivalently                                     0.0   \n",
       "part of                                          0.0   \n",
       "whereas                                          0.0   \n",
       "maximum entropy                                  0.0   \n",
       "positive edges                                   1.0   \n",
       "lower status                                     0.0   \n",
       "guha                                             0.0   \n",
       "positive relationships                           0.0   \n",
       "social computing                                 0.0   \n",
       "\n",
       "                        Nq119A7Qa4hPWNSThUX3S8Y8k313  \\\n",
       "entity_text                                            \n",
       "whether                                          0.0   \n",
       "slashdot                                         1.0   \n",
       "wikipedia                                        1.0   \n",
       "social network                                   1.0   \n",
       "related work                                     0.0   \n",
       "social networks                                  1.0   \n",
       "although                                         0.0   \n",
       "epinions                                         1.0   \n",
       "without                                          0.0   \n",
       "social media                                     1.0   \n",
       "named entities                                   0.0   \n",
       "toward                                           0.0   \n",
       "equivalently                                     0.0   \n",
       "part of                                          0.0   \n",
       "whereas                                          0.0   \n",
       "maximum entropy                                  0.0   \n",
       "positive edges                                   0.0   \n",
       "lower status                                     0.0   \n",
       "guha                                             0.0   \n",
       "positive relationships                           0.0   \n",
       "social computing                                 0.0   \n",
       "\n",
       "                        qV1wemRqtjWRBxqOnqDpbEDE7dQ2  \\\n",
       "entity_text                                            \n",
       "whether                                          0.0   \n",
       "slashdot                                         1.0   \n",
       "wikipedia                                        1.0   \n",
       "social network                                   0.0   \n",
       "related work                                     0.0   \n",
       "social networks                                  0.0   \n",
       "although                                         0.0   \n",
       "epinions                                         1.0   \n",
       "without                                          0.0   \n",
       "social media                                     0.0   \n",
       "named entities                                   0.0   \n",
       "toward                                           0.0   \n",
       "equivalently                                     0.0   \n",
       "part of                                          0.0   \n",
       "whereas                                          0.0   \n",
       "maximum entropy                                  0.0   \n",
       "positive edges                                   0.0   \n",
       "lower status                                     0.0   \n",
       "guha                                             0.0   \n",
       "positive relationships                           0.0   \n",
       "social computing                                 0.0   \n",
       "\n",
       "                        XnqHi69zi9gmO4e7xFe6aK9PEiE3  \\\n",
       "entity_text                                            \n",
       "whether                                          0.0   \n",
       "slashdot                                         1.0   \n",
       "wikipedia                                        1.0   \n",
       "social network                                   1.0   \n",
       "related work                                     0.0   \n",
       "social networks                                  1.0   \n",
       "although                                         0.0   \n",
       "epinions                                         1.0   \n",
       "without                                          0.0   \n",
       "social media                                     1.0   \n",
       "named entities                                   0.0   \n",
       "toward                                           0.0   \n",
       "equivalently                                     NaN   \n",
       "part of                                          NaN   \n",
       "whereas                                          0.0   \n",
       "maximum entropy                                  NaN   \n",
       "positive edges                                   0.0   \n",
       "lower status                                     0.0   \n",
       "guha                                             0.0   \n",
       "positive relationships                           0.0   \n",
       "social computing                                 0.0   \n",
       "\n",
       "                        G8hHT8mWZiXmaJTPIyLj6KdjzVF2  \\\n",
       "entity_text                                            \n",
       "whether                                          0.0   \n",
       "slashdot                                         1.0   \n",
       "wikipedia                                        0.0   \n",
       "social network                                   0.0   \n",
       "related work                                     0.0   \n",
       "social networks                                  0.0   \n",
       "although                                         0.0   \n",
       "epinions                                         NaN   \n",
       "without                                          0.0   \n",
       "social media                                     0.0   \n",
       "named entities                                   NaN   \n",
       "toward                                           NaN   \n",
       "equivalently                                     0.0   \n",
       "part of                                          0.0   \n",
       "whereas                                          NaN   \n",
       "maximum entropy                                  0.0   \n",
       "positive edges                                   NaN   \n",
       "lower status                                     NaN   \n",
       "guha                                             NaN   \n",
       "positive relationships                           NaN   \n",
       "social computing                                 NaN   \n",
       "\n",
       "                        lqmIlg05OpMYR8f6VR9UPN29nWg2  \n",
       "entity_text                                           \n",
       "whether                                          0.0  \n",
       "slashdot                                         1.0  \n",
       "wikipedia                                        1.0  \n",
       "social network                                   0.0  \n",
       "related work                                     0.0  \n",
       "social networks                                  1.0  \n",
       "although                                         0.0  \n",
       "epinions                                         1.0  \n",
       "without                                          0.0  \n",
       "social media                                     1.0  \n",
       "named entities                                   0.0  \n",
       "toward                                           0.0  \n",
       "equivalently                                     0.0  \n",
       "part of                                          0.0  \n",
       "whereas                                          0.0  \n",
       "maximum entropy                                  0.0  \n",
       "positive edges                                   0.0  \n",
       "lower status                                     0.0  \n",
       "guha                                             0.0  \n",
       "positive relationships                           0.0  \n",
       "social computing                                 0.0  "
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dataset_agreement[~dataset_agreement.index.duplicated(keep='first')]\n",
    "df['null_count'] = df.isnull().sum(axis=1)\n",
    "df = df.sort_values('null_count', ascending=True)\n",
    "df_temp = df\n",
    "dataset_agreement = df.drop('null_count', axis=1)\n",
    "selected_users = dataset_agreement.ix[:, :7].dropna(thresh=6)\n",
    "selected_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users = ['diuSsjdsEoWWDTejfcpU6vaAbjt1', 'YdJDigrdTZUOiUKMsMv1ciWxHtc2', 'Nq119A7Qa4hPWNSThUX3S8Y8k313', 'qV1wemRqtjWRBxqOnqDpbEDE7dQ2', 'XnqHi69zi9gmO4e7xFe6aK9PEiE3', 'lqmIlg05OpMYR8f6VR9UPN29nWg2']\n",
      "kappa 0.5\n",
      "kappa 0.5882352941176469\n",
      "kappa 0.6666666666666666\n",
      "kappa 0.5\n",
      "kappa 0.5882352941176469\n",
      "kappa 0.3913043478260871\n",
      "kappa 0.4545454545454546\n",
      "kappa 0.7199999999999999\n",
      "kappa 0.3913043478260871\n",
      "kappa 0.6956521739130435\n",
      "kappa 0.5384615384615385\n",
      "kappa 0.8771929824561402\n",
      "kappa 0.6956521739130435\n",
      "kappa 0.6164383561643837\n",
      "\n",
      "14\n",
      "0.5874063307148384\n"
     ]
    }
   ],
   "source": [
    "users = [\"diuSsjdsEoWWDTejfcpU6vaAbjt1\", \"YdJDigrdTZUOiUKMsMv1ciWxHtc2\", \"Nq119A7Qa4hPWNSThUX3S8Y8k313\", \"qV1wemRqtjWRBxqOnqDpbEDE7dQ2\", \"XnqHi69zi9gmO4e7xFe6aK9PEiE3\", \"lqmIlg05OpMYR8f6VR9UPN29nWg2\"]\n",
    "print('users =', users)\n",
    "\n",
    "dataset_agreement1 = selected_users[users]\n",
    "raters = [list(dataset_agreement1[\"diuSsjdsEoWWDTejfcpU6vaAbjt1\"])\n",
    "        ,list(dataset_agreement1[\"YdJDigrdTZUOiUKMsMv1ciWxHtc2\"])\n",
    "        ,list(dataset_agreement1[\"Nq119A7Qa4hPWNSThUX3S8Y8k313\"])\n",
    "        ,list(dataset_agreement1[\"qV1wemRqtjWRBxqOnqDpbEDE7dQ2\"])\n",
    "        ,list(dataset_agreement1[\"XnqHi69zi9gmO4e7xFe6aK9PEiE3\"])\n",
    "#         ,list(dataset_agreement1[\"G8hHT8mWZiXmaJTPIyLj6KdjzVF2\"])\n",
    "        ,list(dataset_agreement1[\"lqmIlg05OpMYR8f6VR9UPN29nWg2\"])\n",
    "         ]\n",
    "\n",
    "# taskdata = ([[0,str(i),str(rater1[i])] for i in xrange(0, len(dataset_agreement1))] \n",
    "#             + [[1,str(i),str(rater2[i])] for i in range(0, len(dataset_agreement1))]\n",
    "#            + [[1,str(i),str(rater3[i])] for i in range(0, len(dataset_agreement1))]\n",
    "#            + [[1,str(i),str(rater4[i])] for i in range(0, len(dataset_agreement1))]\n",
    "#            + [[1,str(i),str(rater5[i])] for i in range(0, len(dataset_agreement1))]\n",
    "#            + [[1,str(i),str(rater6[i])] for i in range(0, len(dataset_agreement1))]\n",
    "#            + [[1,str(i),str(rater7[i])] for i in range(0, len(dataset_agreement1))]\n",
    "#            )\n",
    "# print(taskdata)\n",
    "\n",
    "kappas = []\n",
    "for usr1 in range(0, len(users)):\n",
    "    for usr2 in range(0, len(users)):\n",
    "        if(usr1 == usr2 or usr1 < usr2 or (usr1 == 3 and usr2 == 0)): continue\n",
    "        taskdata = ([[usr1,str(i),str(raters[usr1][i])] for i in range(0, len(dataset_agreement1))] + [[usr2,str(i),str(raters[usr2][i])] for i in range(0, len(dataset_agreement1))])\n",
    "        ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "        kappa_val = ratingtask.kappa()\n",
    "        print(\"kappa \" +str(kappa_val))\n",
    "        kappas.append(kappa_val)\n",
    "        \n",
    "\n",
    "#print('entities annotated =', dataset_agreement[[\"'user_2'\", \"'user_6'\", \"'user_8'\", \"'user_9'\"]].iloc[:16].index)\n",
    "\n",
    "# ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "# print(\"kappa \" +str(ratingtask.kappa()))\n",
    "# print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "#print(\"alpha \" +str(ratingtask.alpha()))\n",
    "#print(\"scotts \" + str(ratingtask.pi()))\n",
    "print('')\n",
    "\n",
    "print(len(kappas))\n",
    "print(sum(kappas)/len(kappas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(0.2 + 0.8518518518518519 + 0.8461538461538461 + 0.12195121951219512 + 0.05263157894736842 + 0.8608695652173913) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[\"\\'user_1\\'\" \"\\'user_4\\'\" \"\\'user_10\\'\"] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-115-cfdde4ffd424>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset_agreement1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_agreement\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"'user_1'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'user_4'\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'user_10'\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m35\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mrater1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_agreement1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"'user_1'\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrater4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_agreement1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"'user_4'\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrater10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_agreement1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"'user_10'\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2051\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2052\u001b[0m             \u001b[0;31m# either boolean or fancy integer index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2053\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2054\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2055\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_getitem_array\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2095\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2096\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2097\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_to_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2098\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter)\u001b[0m\n\u001b[1;32m   1228\u001b[0m                 \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s not in index'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mobjarr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_values_from_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '[\"\\'user_1\\'\" \"\\'user_4\\'\" \"\\'user_10\\'\"] not in index'"
     ]
    }
   ],
   "source": [
    "dataset_agreement1 = dataset_agreement[[\"'user_1'\", \"'user_4'\", \"'user_10'\"]].iloc[22:35]\n",
    "\n",
    "rater1 = list(dataset_agreement1[\"'user_1'\"])\n",
    "rater4 = list(dataset_agreement1[\"'user_4'\"])\n",
    "rater10 = list(dataset_agreement1[\"'user_10'\"])\n",
    "\n",
    "taskdata = [[0,str(i),str(rater1[i])] for i in range(0,len(rater1))] + [[1,str(i),str(rater4[i])] for i in range(0,len(rater4))] + [[2,str(i),str(rater10[i])] for i in range(0,len(rater10))]\n",
    "\n",
    "print('users =', \"'user_1'\", \"'user_4'\", \"'user_10'\")\n",
    "#print('entities annotated =', dataset_agreement[[\"'user_1'\", \"'user_4'\", \"'user_10'\"]].iloc[22:35].index)\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "\n",
    "# users = [\"'user_1'\", \"'user_4'\", \"'user_10'\"]\n",
    "\n",
    "# for user in users:\n",
    "#     for user2 in users:\n",
    "#         if user != user2:\n",
    "#             taskdata = ([[0, str(i), str(list(dataset_agreement1[user])[i])] for i in range(0, len(dataset_agreement1))] \n",
    "#                         + [[1,str(i),str(list(dataset_agreement1[user2])[i])] for i in range(0, len(dataset_agreement1))])\n",
    "#             print('users =', user, user2)\n",
    "#             ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "#             print(\"kappa \" +str(ratingtask.kappa()))\n",
    "#             print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25415457208371434"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.09900990099009897 + 0.5301204819277109 + 0.1333333333333332) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 663,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users = 'user_3' 'user_5' 'user_7'\n",
      "fleiss 0.35714285714285704\n",
      "\n",
      "users = 'user_3' 'user_5'\n",
      "kappa 0.6666666666666667\n",
      "\n",
      "users = 'user_3' 'user_7'\n",
      "kappa 0.0\n",
      "\n",
      "users = 'user_5' 'user_3'\n",
      "kappa 0.6666666666666667\n",
      "\n",
      "users = 'user_5' 'user_7'\n",
      "kappa 0.39999999999999997\n",
      "\n",
      "users = 'user_7' 'user_3'\n",
      "kappa 0.0\n",
      "\n",
      "users = 'user_7' 'user_5'\n",
      "kappa 0.39999999999999997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_agreement1 = dataset_agreement[[\"'user_3'\", \"'user_5'\", \"'user_7'\"]].iloc[16:22]\n",
    "\n",
    "rater3 = list(dataset_agreement1[\"'user_3'\"])\n",
    "rater5 = list(dataset_agreement1[\"'user_5'\"])\n",
    "rater7 = list(dataset_agreement1[\"'user_7'\"])\n",
    "\n",
    "taskdata = [[0,str(i),str(rater3[i])] for i in range(0,len(rater3))] + [[1,str(i),str(rater5[i])] for i in range(0,len(rater5))] + [[2,str(i),str(rater7[i])] for i in range(0,len(rater7))]\n",
    "\n",
    "print('users =', \"'user_3'\", \"'user_5'\", \"'user_7'\")\n",
    "#print('entities annotated =', dataset_agreement[[\"'user_3'\", \"'user_5'\", \"'user_7'\"]].iloc[16:22].index)\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "#print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "#print(\"alpha \" +str(ratingtask.alpha()))\n",
    "#print(\"scotts \" + str(ratingtask.pi()))\n",
    "print('')\n",
    "\n",
    "users = [\"'user_3'\", \"'user_5'\", \"'user_7'\"]\n",
    "\n",
    "for user in users:\n",
    "    for user2 in users:\n",
    "        if user != user2:\n",
    "            taskdata = ([[0, str(i), str(list(dataset_agreement1[user])[i])] for i in range(0, len(dataset_agreement1))] \n",
    "                        + [[1,str(i),str(list(dataset_agreement1[user2])[i])] for i in range(0, len(dataset_agreement1))])\n",
    "            print('users =', user, user2)\n",
    "            ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "            print(\"kappa \" +str(ratingtask.kappa()))\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.35555555555555557"
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.6666666666666667 + 0.39999999999999997) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.366206601528793"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.48890967694710885 + 0.25415457208371434 + 0.35555555555555557) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> Method Entities </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mvall\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3744: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  regex=regex)\n"
     ]
    }
   ],
   "source": [
    "cleanup_nums = {\"relevant\":     {\"relevant\": 1, \"irrelevant\": 0}}\n",
    "method_annotated.replace(cleanup_nums, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "method_agreement = pd.DataFrame(index = method_annotated.entity_text.unique())\n",
    "\n",
    "for user in method_annotated.user_id.unique():\n",
    "    annotation = method_annotated.loc[method_annotated['user_id'] == user][['entity_text', 'relevant']]\n",
    "    annotation = annotation.rename(columns={'relevant' : user})\n",
    "    method_agreement = method_agreement.merge(annotation, left_index=True, right_on='entity_text', how='left').set_index('entity_text')\n",
    "    method_agreement_t = method_agreement.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 664,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleiss 0.2461719670200236\n",
      "\n",
      "users = 'user_2' 'user_6'\n",
      "kappa 0.14285714285714285\n",
      "\n",
      "users = 'user_2' 'user_8'\n",
      "kappa 0.33884297520661155\n",
      "\n",
      "users = 'user_2' 'user_9'\n",
      "kappa 0.022900763358778626\n",
      "\n",
      "users = 'user_6' 'user_2'\n",
      "kappa 0.14285714285714285\n",
      "\n",
      "users = 'user_6' 'user_8'\n",
      "kappa 0.13513513513513514\n",
      "\n",
      "users = 'user_6' 'user_9'\n",
      "kappa 0.2\n",
      "\n",
      "users = 'user_8' 'user_2'\n",
      "kappa 0.33884297520661155\n",
      "\n",
      "users = 'user_8' 'user_6'\n",
      "kappa 0.13513513513513514\n",
      "\n",
      "users = 'user_8' 'user_9'\n",
      "kappa 0.6595744680851063\n",
      "\n",
      "users = 'user_9' 'user_2'\n",
      "kappa 0.022900763358778626\n",
      "\n",
      "users = 'user_9' 'user_6'\n",
      "kappa 0.2\n",
      "\n",
      "users = 'user_9' 'user_8'\n",
      "kappa 0.6595744680851063\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method_agreement1 = method_agreement[[\"'user_2'\", \"'user_6'\", \"'user_8'\", \"'user_9'\"]].iloc[0:16]\n",
    "\n",
    "rater2 = list(method_agreement[\"'user_2'\"])\n",
    "rater6 = list(method_agreement[\"'user_6'\"])\n",
    "rater8 = list(method_agreement[\"'user_8'\"])\n",
    "rater9 = list(method_agreement[\"'user_9'\"])\n",
    "\n",
    "taskdata = ([[0,str(i),str(rater2[i])] for i in range(0,len(method_agreement1))] + [[1,str(i),str(rater6[i])] for i in range(0,len(method_agreement1))] +\n",
    "        [[2,str(i),str(rater9[i])] for i in range(0,len(method_agreement1))] + [[3,str(i),str(rater8[i])] for i in range(0,len(method_agreement1))])\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "#print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "#print(\"alpha \" +str(ratingtask.alpha()))\n",
    "#print(\"scotts \" + str(ratingtask.pi()))\n",
    "\n",
    "print('')\n",
    "\n",
    "users = [\"'user_2'\", \"'user_6'\", \"'user_8'\", \"'user_9'\"]\n",
    "\n",
    "for user in users:\n",
    "    for user2 in users:\n",
    "        if user != user2:\n",
    "            taskdata = ([[0, str(i), str(list(method_agreement1[user])[i])] for i in range(0, len(method_agreement1))] \n",
    "                        + [[1,str(i),str(list(method_agreement1[user2])[i])] for i in range(0, len(method_agreement1))])\n",
    "            print('users =', user, user2)\n",
    "            ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "            print(\"kappa \" +str(ratingtask.kappa()))\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24988508077379576"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.14285714285714285 + 0.33884297520661155 + 0.022900763358778626 + 0.13513513513513514 + 0.2 + 0.6595744680851063) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleiss 0.38596491228070157\n",
      "\n",
      "users = 'user_3' 'user_5'\n",
      "kappa 0.3589743589743589\n",
      "\n",
      "users = 'user_3' 'user_7'\n",
      "kappa 0.4736842105263157\n",
      "\n",
      "users = 'user_5' 'user_3'\n",
      "kappa 0.3589743589743589\n",
      "\n",
      "users = 'user_5' 'user_7'\n",
      "kappa 0.3243243243243242\n",
      "\n",
      "users = 'user_7' 'user_3'\n",
      "kappa 0.4736842105263157\n",
      "\n",
      "users = 'user_7' 'user_5'\n",
      "kappa 0.3243243243243242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method_agreement1 = method_agreement[[\"'user_3'\", \"'user_5'\", \"'user_7'\"]].iloc[17:32]\n",
    "\n",
    "rater3 = list(method_agreement1[\"'user_3'\"])\n",
    "rater5 = list(method_agreement1[\"'user_5'\"])\n",
    "rater7 = list(method_agreement1[\"'user_7'\"])\n",
    "\n",
    "taskdata = ([[0,str(i),str(rater3[i])] for i in range(0,len(rater3))] + [[1,str(i),str(rater5[i])] for i in range(0,len(rater5))] +\n",
    "        [[2,str(i),str(rater7[i])] for i in range(0,len(rater7))])\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "#print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "#print(\"alpha \" +str(ratingtask.alpha()))\n",
    "#print(\"scotts \" + str(ratingtask.pi()))\n",
    "\n",
    "print('')\n",
    "\n",
    "users = [\"'user_3'\", \"'user_5'\", \"'user_7'\"]\n",
    "\n",
    "for user in users:\n",
    "    for user2 in users:\n",
    "        if user != user2:\n",
    "            taskdata = ([[0, str(i), str(list(method_agreement1[user])[i])] for i in range(0, len(method_agreement1))] \n",
    "                        + [[1,str(i),str(list(method_agreement1[user2])[i])] for i in range(0, len(method_agreement1))])\n",
    "            print('users =', user, user2)\n",
    "            ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "            print(\"kappa \" +str(ratingtask.kappa()))\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38566096460833293"
      ]
     },
     "execution_count": 674,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.3589743589743589 + 0.4736842105263157 + 0.3243243243243242) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleiss 0.3251173708920189\n",
      "\n",
      "users = 'user_1' 'user_4'\n",
      "kappa 0.554263565891473\n",
      "\n",
      "users = 'user_1' 'user_10'\n",
      "kappa 0.1732026143790849\n",
      "\n",
      "users = 'user_4' 'user_1'\n",
      "kappa 0.554263565891473\n",
      "\n",
      "users = 'user_4' 'user_10'\n",
      "kappa 0.2812500000000001\n",
      "\n",
      "users = 'user_10' 'user_1'\n",
      "kappa 0.1732026143790849\n",
      "\n",
      "users = 'user_10' 'user_4'\n",
      "kappa 0.2812500000000001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "method_agreement1 = method_agreement[[\"'user_1'\", \"'user_4'\", \"'user_10'\"]].iloc[32:55]\n",
    "\n",
    "rater1 = list(method_agreement1[\"'user_1'\"])\n",
    "rater4 = list(method_agreement1[\"'user_4'\"])\n",
    "rater10 = list(method_agreement1[\"'user_10'\"])\n",
    "\n",
    "taskdata = ([[0,str(i),str(rater1[i])] for i in range(0,len(rater1))] + [[1,str(i),str(rater4[i])] for i in range(0,len(rater4))] +\n",
    "        [[2,str(i),str(rater10[i])] for i in range(0,len(rater10))])\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "#print(\"kappa \" +str(ratingtask.kappa()))\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))\n",
    "#print(\"alpha \" +str(ratingtask.alpha()))\n",
    "#print(\"scotts \" + str(ratingtask.pi()))\n",
    "\n",
    "print('')\n",
    "\n",
    "users = [\"'user_1'\", \"'user_4'\", \"'user_10'\"]\n",
    "\n",
    "for user in users:\n",
    "    for user2 in users:\n",
    "        if user != user2:\n",
    "            taskdata = ([[0, str(i), str(list(method_agreement1[user])[i])] for i in range(0, len(method_agreement1))] \n",
    "                        + [[1,str(i),str(list(method_agreement1[user2])[i])] for i in range(0, len(method_agreement1))])\n",
    "            print('users =', user, user2)\n",
    "            ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "            print(\"kappa \" +str(ratingtask.kappa()))\n",
    "            print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3362387267568527"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.554263565891473 + 0.1732026143790849 + 0.2812500000000001) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32392825737966047"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(0.24988508077379576 + 0.38566096460833293 + 0.3362387267568527 ) / 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<H3> All Entities </H3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleiss 0.4221668742216687\n"
     ]
    }
   ],
   "source": [
    "paper1_agreement = pd.concat([dataset_agreement[[\"'user_2'\", \"'user_6'\", \"'user_8'\", \"'user_9'\"]].iloc[:16], method_agreement[[\"'user_2'\", \"'user_6'\", \"'user_8'\", \"'user_9'\"]].iloc[:16]])\n",
    "\n",
    "rater2 = list(paper1_agreement[\"'user_2'\"])\n",
    "rater6 = list(paper1_agreement[\"'user_6'\"])\n",
    "rater8 = list(paper1_agreement[\"'user_8'\"])\n",
    "rater9 = list(paper1_agreement[\"'user_9'\"])\n",
    "\n",
    "taskdata = ([[0,str(i),str(rater2[i])] for i in range(0,len(rater2))] + [[1,str(i),str(rater6[i])] for i in range(0,len(rater2))] +\n",
    "        [[2,str(i),str(rater9[i])] for i in range(0, len(rater2))] + [[3,str(i),str(rater8[i])] for i in range(0, len(rater2))])\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleiss 0.3004739336492891\n"
     ]
    }
   ],
   "source": [
    "paper1_agreement = pd.concat([dataset_agreement[[\"'user_1'\", \"'user_4'\", \"'user_10'\"]].iloc[22:35], method_agreement[[\"'user_1'\", \"'user_4'\", \"'user_10'\"]].iloc[32:55]])\n",
    "\n",
    "rater1 = list(paper1_agreement[\"'user_1'\"])\n",
    "rater4 = list(paper1_agreement[\"'user_4'\"])\n",
    "rater10 = list(paper1_agreement[\"'user_10'\"])\n",
    "\n",
    "taskdata = ([[0,str(i),str(rater1[i])] for i in range(0,len(rater1))] + [[1,str(i),str(rater4[i])] for i in range(0,len(rater4))] +\n",
    "        [[2,str(i),str(rater10[i])] for i in range(0, len(rater10))] )\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fleiss 0.36936936936936915\n"
     ]
    }
   ],
   "source": [
    "paper1_agreement = pd.concat([method_agreement[[\"'user_3'\", \"'user_5'\", \"'user_7'\"]].iloc[17:32], dataset_agreement[[\"'user_3'\", \"'user_5'\", \"'user_7'\"]].iloc[16:22]])\n",
    "\n",
    "rater1 = list(paper1_agreement[\"'user_3'\"])\n",
    "rater4 = list(paper1_agreement[\"'user_5'\"])\n",
    "rater10 = list(paper1_agreement[\"'user_7'\"])\n",
    "\n",
    "taskdata = ([[0,str(i),str(rater1[i])] for i in range(0,len(rater1))] + [[1,str(i),str(rater4[i])] for i in range(0,len(rater4))] +\n",
    "        [[2,str(i),str(rater10[i])] for i in range(0, len(rater10))] )\n",
    "\n",
    "ratingtask = agreement.AnnotationTask(data=taskdata)\n",
    "print(\"fleiss \" + str(ratingtask.multi_kappa()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3640033924134423"
      ]
     },
     "execution_count": 687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " (0.4221668742216687 +0.3004739336492891 +0.36936936936936915) / 3"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
